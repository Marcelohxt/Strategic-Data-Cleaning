








# Versão da Linguagem Python
from platform import python_version
print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())


# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:
# pip install -U nome_pacote

# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:
# !pip install nome_pacote==versão_desejada

# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.

# Instala o pacote watermark. 
# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.
# !pip install -q -U watermark


# Imports
import math
import sys, os
import numpy as np
import pandas as pd
import watermark 


# Vamos adicionar caminho para os módulos Python
sys.path.append(os.path.abspath(os.path.join('modulos')))
from estrategia1 import *
from estrategia2 import *
from estrategia3 import *


#!pip install -q plotly
#!pip install -q numpy 
#!pip install -q pandas 
#!pip install -q -U watermark
#!pip install -q missingno
#!pip install -q category_encoders
#!pip install -q xlrd


!pip install -q xlrd


pd.set_option('display.max_columns', 100)


# Versões dos pacotes usados neste jupyter notebook
%reload_ext watermark
%watermark -a "Data Science Academy" --iversions





# Criamos uma lista para identificar valores ausentes
lista_labels_valores_ausentes = ["n/a", "na", "undefined"]


# Carrega o dataset
dataset = pd.read_csv("dados/dataset.csv", na_values = lista_labels_valores_ausentes)


# Shape
dataset.shape


# Amostra de dados
dataset.head()


# Carregando o dicionário de dados
dicionario = pd.read_excel("dados/Dicionario.xlsx")


# Shape
dicionario.shape


# Amostra de dados
dicionario.head()





# Info
dataset.info()


# Estatísticas descritivas
dataset.describe()





# Shape
dataset.shape


# Shape
dicionario.shape





# Concatena os dataframes
df_compara_colunas = pd.concat([pd.Series(dataset.columns.tolist()), 
                                dicionario['Fields']], 
                               axis = 1)


# Renomeia as colunas
df_compara_colunas.rename(columns = {0: 'Coluna no Dataset', 'Fields': 'Coluna no Dicionario'}, 
                          inplace = True)


# Visualiza
df_compara_colunas





dataset[['Dur. (ms)', 'Dur. (ms).1']]





# Renomeia colunas
dataset.rename(columns = {'Dur. (ms)': 'Dur (s)', 
                          'Dur. (ms).1': 'Dur (ms)', 
                          'Start ms': 'Start Offset (ms)', 
                          'End ms': 'End Offset (ms)'}, 
               inplace = True)


# Lista de colunas do dataset
dataset.columns.tolist()





help(func_calc_percentual_valores_ausentes)


# Verifica o percentual de valores ausentes
# Função do módulo estratégia 1
func_calc_percentual_valores_ausentes(dataset)


# Cria tabela com valores ausentes
df_missing = func_calc_percentual_valores_ausentes_coluna(dataset)


# Visualiza
df_missing





# Colunas que serão removidas
colunas_para_remover = df_missing[df_missing['% de Valores Ausentes'] >= 30.00].index.tolist()


# Colunas que serão removidas
colunas_para_remover





# Colunas que serão removidas
colunas_para_remover = [col for col in colunas_para_remover if col not in ['TCP UL Retrans. Vol (Bytes)',
    'TCP DL Retrans. Vol (Bytes)']]


# Colunas que serão removidas
colunas_para_remover


# Drop das colunas e cria outro dataframe
dataset_clean = dataset.drop(colunas_para_remover, axis = 1)


# Shape
dataset_clean.shape





func_calc_percentual_valores_ausentes(dataset_clean)


func_calc_percentual_valores_ausentes_coluna(dataset_clean)








# Imputação com Preenchimento Reverso
fix_missing_bfill(dataset_clean, 'TCP UL Retrans. Vol (Bytes)')


# Imputação com Preenchimento Reverso
fix_missing_bfill(dataset_clean, 'TCP DL Retrans. Vol (Bytes)')





dataset_clean['Avg RTT DL (ms)'].skew(skipna = True)


dataset_clean['Avg RTT UL (ms)'].skew(skipna = True)








# Imputação com Preenchimento Progressivo
fix_missing_ffill(dataset_clean, 'Avg RTT DL (ms)')


# Imputação com Preenchimento Progressivo
fix_missing_ffill(dataset_clean, 'Avg RTT UL (ms)')





func_calc_percentual_valores_ausentes(dataset_clean)


func_calc_percentual_valores_ausentes_linha(dataset_clean)


func_calc_percentual_valores_ausentes_coluna(dataset_clean)


dataset_clean.info()





# Imputação de variáveis categóricas
fix_missing_value(dataset_clean, 'Handset Type', 'unknown')
fix_missing_value(dataset_clean, 'Handset Manufacturer', 'unknown')





func_calc_percentual_valores_ausentes(dataset_clean)


func_calc_percentual_valores_ausentes_linha(dataset_clean)





# Drop de linhas com valores ausentes
drop_rows_with_missing_values(dataset_clean)


func_calc_percentual_valores_ausentes(dataset_clean)


# Shape
dataset_clean.shape





dataset_clean.dtypes


dataset_clean





# Converte para datetime
convert_to_datetime(dataset_clean, ['Start', 'End'])


# Extrai as colunas do tipo object
string_columns = dataset_clean.select_dtypes(include = 'object').columns.tolist()


# Visualiza
string_columns


# Converte para string
convert_to_string(dataset_clean, string_columns)





# Lista de colunas para conversão
int_cols = ['Bearer Id', 'IMSI', 'MSISDN/Number', 'IMEI',]


# Converte para int
convert_to_int(dataset_clean, int_cols)


dataset_clean.dtypes


# Vamos checar se há registros duplicados
drop_duplicates(dataset_clean)





# Conversão e comparação
temp_df = dataset_clean[['Dur (s)', 'Dur (ms)']].copy()
multiply_by_factor(temp_df, ['Dur (ms)'], 1/1000)
temp_df['comparison'] = (temp_df['Dur (s)'] == temp_df['Dur (ms)'].apply(math.floor))


temp_df


# As duas colunas são iguais?
print(all(temp_df['comparison']))





# Drop de coluna
drop_columns(dataset_clean, ['Dur (s)'])








# Cria o objeto trata outlier
trata_outlier = TrataOutlier(dataset_clean)


# Lista de colunas float64
lista_colunas = dataset_clean.select_dtypes('float64').columns.tolist()


lista_colunas


# Visão geral dos outliers
trata_outlier.getOverview(lista_colunas)


# Replace dos outliers
trata_outlier.replace_outliers_with_fences(lista_colunas)


# Visão geral dos outliers
trata_outlier.getOverview(lista_colunas)








dataset_clean['Social Media Data Volume (Bytes)'] = dataset_clean['Social Media UL (Bytes)'] + dataset_clean['Social Media DL (Bytes)']


dataset_clean['Google Data Volume (Bytes)'] = dataset_clean['Google UL (Bytes)'] + dataset_clean['Google DL (Bytes)']


dataset_clean['Email Data Volume (Bytes)'] = dataset_clean['Email UL (Bytes)'] + dataset_clean['Email DL (Bytes)']


dataset_clean['Youtube Data Volume (Bytes)'] = dataset_clean['Youtube UL (Bytes)'] + dataset_clean['Youtube DL (Bytes)']


dataset_clean['Netflix Data Volume (Bytes)'] = dataset_clean['Netflix UL (Bytes)'] + dataset_clean['Netflix DL (Bytes)']


dataset_clean['Gaming Data Volume (Bytes)'] = dataset_clean['Gaming UL (Bytes)'] + dataset_clean['Gaming DL (Bytes)']


dataset_clean['Other Data Volume (Bytes)'] = dataset_clean['Other UL (Bytes)'] + dataset_clean['Other DL (Bytes)']


dataset_clean['Total Data Volume (Bytes)'] = dataset_clean['Total UL (Bytes)'] + dataset_clean['Total DL (Bytes)']


dataset_clean.info()


dataset_clean.shape





# Salvando os dados
dataset_clean.to_csv('dados/dataset_clean.csv')









































































































































































































